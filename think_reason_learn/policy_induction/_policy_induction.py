"""Policy Induction.

An interpretable ensemble framework for
generated by LLMs.
"""

from __future__ import annotations

from typing import List, Self, Tuple, Generator, Any, Sequence
from typing import Dict, Literal, Optional
import asyncio
import logging
from copy import deepcopy
from uuid import uuid4
from pathlib import Path
from os import PathLike
import os

import numpy as np
import numpy.typing as npt
import pandas as pd
from pydantic import BaseModel, Field

from think_reason_learn.core.llms import LLMChoice, llm, TokenCounter
from think_reason_learn.core.exceptions import DataError, LLMError
from ._prompts import (
    max_policy_num_tag,
    POLICY_GEN_INSTRUCTIONS,
    POLICY_PREDICT_INSTRUCTIONS,
)

import re

logger = logging.getLogger(__name__)


class Policies(BaseModel):
    policies: List[str] = Field(..., description="The list of generated policies.")


class Answer(BaseModel):
    answer: Literal["YES", "NO"]


class PolicyInduction:
    """Interpretable ensemble binary classifier.

    Args:
        gen_llmc: LLMs to use for policy generation, in priority order.
        predict_llmc: LLM to use for prediction.
        gen_temperature: Sampling temperature for policy generation.
        predict_temperature: Sampling temperature for policy prediction.
        llm_semaphore_limit: Max concurrent LLM calls.
        max_policy_length: Maximum rows of policies to generate. Max 500
        class_ratio: Ratio of YES to NO samples to use as
            context for policy generation.
        max_samples_as_context: Number of samples used as context in a round
            of policy generation. Max 100
        p_predict_update_interval: Logging interval of policy prediction.
        save_path: Directory to save checkpoints/models.
        name: Name of the policy-induction instance.
        random_state: Random seed.
    """

    def __init__(
        self,
        gen_llmc: List[LLMChoice],
        predict_llmc: List[LLMChoice] | None = None,
        gen_temperature: float = 0.0,
        predict_temperature: float = 0.0,
        llm_semaphore_limit: int = 3,
        max_policy_length: int = 200,
        class_ratio: Tuple[float, float] = (1.0, 1.0),
        max_samples_as_context: int = 10,
        p_predict_update_interval: int = 10,
        save_path: str | PathLike[str] | None = None,
        name: str | None = None,
        random_state: int = 42,
    ):
        locals_dict = deepcopy(locals())
        del locals_dict["self"]
        self._verify_input_data(**locals_dict)

        self.gen_llmc = gen_llmc
        self.predict_llmc = predict_llmc or gen_llmc
        self.gen_temperature = gen_temperature
        self.predict_temperature = predict_temperature
        self._llm_semaphore_limit = llm_semaphore_limit

        self.class_ratio = class_ratio
        self.max_policy_length = max_policy_length
        self.random_state = random_state
        self.max_samples_as_context = max_samples_as_context

        self.name: str = self._get_name(name)
        self.save_path: Path = self._set_save_path(save_path)
        self.p_predict_update_interval = p_predict_update_interval

        self._token_counter: TokenCounter = TokenCounter()
        self._llm_semaphore = asyncio.Semaphore(llm_semaphore_limit)  # async with
        self._pgen_instructions_template: str | None = None
        self._task_description: str | None = None

        self._X: pd.DataFrame | None = None
        self._y: npt.NDArray[np.str_] | None = None

        self._policy_memory: pd.DataFrame = self._set_initial_memory_df()

    @property
    def llm_semaphore_limit(self) -> int:
        return self._llm_semaphore_limit

    @llm_semaphore_limit.setter
    def llm_semaphore_limit(self, value: int) -> None:
        self._llm_semaphore_limit = value
        self._llm_semaphore = asyncio.Semaphore(value)

    @property
    def token_usage(self) -> TokenCounter:
        """Get the token counter for the Policy Induction."""
        return self._token_counter

    @property
    def task_description(self) -> str | None:
        """Get the task description."""
        return self._task_description

    @property
    def policy_gen_instructions_template(self) -> str | None:
        """Get the policy generation instructions template."""
        return self._pgen_instructions_template

    def _verify_input_data(self, **kwargs: Any) -> None:
        val = kwargs["max_policy_length"]
        if not (0 < val < 500):
            raise ValueError("max_policy_length must be > 0 and < 500")
        val = kwargs["class_ratio"]
        if not (len(val) == 2 and all(cr > 0 for cr in val)):
            raise ValueError("class_ratio must be a tuple of two elements each > 0")
        val = kwargs["llm_semaphore_limit"]
        if not (val > 0):
            raise ValueError("llm_semaphore_limit must be > 0")
        val = kwargs["p_predict_update_interval"]
        if not (val > 0):
            raise ValueError("p_predict_update_interval must be > 0")
        val = kwargs["save_path"]
        if not (val is None or isinstance(val, (str, Path))):
            raise ValueError("save_path must be None, a string, or a Path")
        val = kwargs["name"]
        if not (val is None or isinstance(val, str)):
            raise ValueError("name must be None or a string")
        val = kwargs["gen_temperature"]
        if not (0 <= val <= 2):
            raise ValueError("gen_temperature must be >= 0 and <= 2")
        val = kwargs["predict_temperature"]
        if not (0 <= val <= 2):
            raise ValueError("predict_temperature must be >= 0 and <= 2")

    def _get_name(self, name: str | None) -> str:
        if name is None:
            name = str(uuid4()).replace("-", "_")
            logger.debug(f"No name provided. Assigned name: {name}")

        if not re.match(r"^[a-zA-Z0-9_]+$", name):
            raise ValueError("Name must be only alphanumeric and underscores")
        return name

    def _set_save_path(self, save_path: str | PathLike[str] | None) -> Path:
        if save_path is None:
            return (Path(os.getcwd()) / "policy_induction" / self.name).resolve()
        else:
            save_path = Path(save_path).resolve()
            if save_path.is_file():
                raise ValueError("Please provide a directory, not a file.")
            return save_path

    def _set_initial_memory_df(self) -> pd.DataFrame:
        """Initialize the policy memory DataFrame with explicit dtypes.

        Returns:
            pd.DataFrame: A DataFrame with the following columns:
                - policy (str): The text of the policy.
                - predictions (object): The corresponding binary predictions
                  for each sample in X (keeps positional alignment with X).
                - weight (float): The weight assigned to this policy, default 0.
            The DataFrame has an empty string-based index named 'id'.
        """
        return pd.DataFrame(
            {
                "policy": pd.Series([], dtype=str),
                "predictions": pd.Series([], dtype=object),
                "weight": pd.Series([], dtype=float),
            },
            index=pd.Index([], dtype=str, name="id"),
        )

    def get_memory(self) -> pd.DataFrame:
        """Get memory dataframe.

        Returns:
            pd.DataFrame: A DataFrame with the following columns:
                - policy (str): The text of the policy.
                - predictions (object): The corresponding binary predictions
                  for each sample in X (keeps positional alignment with X).
                - weight (float): The weight assigned to this policy, default 0.
        """
        return self._policy_memory

    async def set_task(
        self,
        task_description: str | None = None,
        instructions_template: str | None = None,
    ) -> str:
        """Initialize policy generation instructions template.

        This sets the task description for Policy Induction.
        Either sets a custom template or generates one from task description using LLM.
        For most users, LLM generation is recommended over custom templates.

        Args:
            instructions_template: Custom template to use. Must contain
                '<max_policy_length>' tag. If None, generates template
                from task_description using LLM.
            task_description: Description of classification task to help LLM generate
                the template.

        Returns:
            The policy generation instructions template.

        Raises:
            ValueError: If template missing required tag or generation fails.
            AssertionError: If both parameters are None.
        """
        assert task_description is not None, "Task_description must be provided"

        self._task_description = task_description

        if instructions_template:
            if max_policy_num_tag not in instructions_template:
                raise ValueError(
                    f"instructions_template must contain the tag "
                    f"'{max_policy_num_tag}'. "
                    "This tag will be replaced with the maximum number of policies "
                    "to generate."
                )
            else:
                self._pgen_instructions_template = instructions_template
                return instructions_template

        async with self._llm_semaphore:
            response = await llm.respond(
                query=f"Generate policies for:\n{task_description}",
                llm_priority=self.gen_llmc,
                response_format=str,
                instructions=POLICY_GEN_INSTRUCTIONS,
                temperature=self.gen_temperature,
            )
        await self._token_counter.append(
            provider=response.provider_model.provider,
            model=response.provider_model.model,
            value=response.total_tokens,
            caller="PolicyInduction._set_tasks",
        )
        if not response.response:
            raise ValueError(
                "Failed to generate policy generation instructions. "
                "Try refining the task description or change the models "
                "for generating policy generation instructions (self.gen_llmc)."
            )
        elif max_policy_num_tag not in response.response:
            raise ValueError(
                "Failed to generate a valid policy generation "
                "instructions template. Please try again."
            )

        if response.average_confidence is not None:
            logger.info(
                "Generated policy generation instructions with "
                f"confidence {response.average_confidence}"
            )
        else:
            logger.info(
                "Generated policy generation instructions. Could not track "
                "confidence of instructions."
            )

        self._pgen_instructions_template = response.response
        return response.response

    def _set_data(self, X: pd.DataFrame, y: Sequence[str], copy_data: bool) -> None:
        if not all(isinstance(item, str) for item in y):  # type: ignore
            raise DataError("y must be a sequence of strings")

        if len(y) != X.shape[0]:
            raise DataError("y and X must have the same number of rows")

        if set(np.unique(y)) != {"YES", "NO"}:
            raise DataError(
                "y must be a sequence of only 'YES' or 'NO' values (case insensitive)"
            )

        y_array = np.array([yi.upper() for yi in y], dtype=np.str_)

        if copy_data:
            self._X = deepcopy(X).reset_index(drop=True)  # type: ignore
            self._y = deepcopy(y_array)
        else:
            self._X = X.reset_index(drop=True)  # type: ignore
            self._y = y_array

        self._policy_memory = self._set_initial_memory_df()

    def _get_policy_gen_instructions(self):
        if not self._pgen_instructions_template:
            raise ValueError(
                "Policy generation instructions template is not set. "
                "Set the template using `set_tasks`."
            )

        return self._pgen_instructions_template.replace(
            max_policy_num_tag, str(self.max_policy_length)
        )

    def _sample(self, n: int) -> Generator[pd.DataFrame, None, None]:
        if self._X is None or self._y is None:
            raise ValueError("X and y must be set")

        rng = np.random.default_rng(self.random_state)
        yes_idx = rng.permutation(np.where(self._y == "YES")[0])
        no_idx = rng.permutation(np.where(self._y == "NO")[0])

        p_yes = self.class_ratio[0] / sum(self.class_ratio)
        want_yes = int(round(n * p_yes))
        want_no = n - want_yes

        taken_y = 0
        taken_n = 0
        len_yes = len(yes_idx)
        len_no = len(no_idx)

        while taken_y < len_yes or taken_n < len_no:
            take_y = min(want_yes, len_yes - taken_y)
            take_n = min(want_no, len_no - taken_n)

            if take_y == 0 and take_n == 0:
                break

            # Fill from remaining if one is short
            if take_y + take_n < n:
                rem = n - take_y - take_n
                if len_yes - taken_y > 0:
                    extra = min(rem, len_yes - taken_y - take_y)
                    take_y += extra
                    rem -= extra
                if rem > 0 and len_no - taken_n > 0:
                    take_n += min(rem, len_no - taken_n - take_n)

            batch = np.concatenate(
                [
                    yes_idx[taken_y : taken_y + take_y],
                    no_idx[taken_n : taken_n + take_n],
                ]
            )
            if batch.size == 0:
                break

            rng.shuffle(batch)
            batch_df = self._X.iloc[batch].copy()  # type: ignore
            batch_df["y"] = self._y[batch]
            yield batch_df

            taken_y += take_y
            taken_n += take_n

    async def _generate_policies(self) -> None:
        if self._X is None:
            raise ValueError("X must be set")

        instructions = self._get_policy_gen_instructions()
        all_policies: List[str] = []
        task_description = self.task_description

        for sample_df in self._sample(self.max_samples_as_context):
            samples_str = ""
            for each_sample in sample_df.to_dict(orient="records"):  # type: ignore
                sample_str = "\n".join(
                    [f"{col}: {val}" for col, val in each_sample.items()]  # type: ignore
                )
                samples_str += f"\n{sample_str};"

            policy_str = "\n".join(all_policies)

            query = (
                "TASK DESCRIPTION:\n"
                f"{task_description}\n\n"
                "EXISTING POLICIES:\n"
                f"{policy_str}\n\n"
                "SAMPLES:\n"
                f"{samples_str}\n\n"
            )
            async with self._llm_semaphore:
                response = await llm.respond(
                    query=query,
                    llm_priority=self.gen_llmc,
                    response_format=Policies,
                    instructions=instructions,
                    temperature=self.gen_temperature,
                )

            await self._token_counter.append(
                provider=response.provider_model.provider,
                model=response.provider_model.model,
                value=response.total_tokens,
                caller="PolicyInduction._generate_policies",
            )

            policies = response.response
            if policies is None:
                raise LLMError(
                    "Could not generate policies. Please try "
                    "again or with a different llm."
                    f"\nQuery: {query[:200]}..."
                    f"\n\nInstructions: {instructions[:200]}..."
                )
            all_policies = policies.policies
            logger.info(f"Generated policies: {len(policies.policies)}")

        policy_lenth = len(all_policies)
        max_id_len = 3
        index = [str(i).zfill(max_id_len) for i in range(policy_lenth)]

        self._policy_memory = pd.DataFrame(
            {
                "policy": all_policies,
                "predictions": [None] * policy_lenth,
                "weight": [0.0] * policy_lenth,
            },
            index=index,  # type: ignore
        )

    def _check_policy_memory(self) -> None:
        """Ensure all policy predictions are valid. If not, set to None."""
        temp_memory = self._policy_memory.dropna(subset=["policy"])
        expected_rows = len(self._X) if self._X is not None else 0
        for idx, val in temp_memory["predictions"].items():
            if val is None:
                continue

            if isinstance(val, pd.Series):
                if len(val) != expected_rows:
                    temp_memory.at[idx, "predictions"] = None
            else:
                temp_memory.at[idx, "predictions"] = None

        self._policy_memory = temp_memory

    async def _single_policy_predict(
        self,
        policy: str,
        samples: pd.DataFrame,
        token_counter: TokenCounter,  # type:
    ) -> Optional[pd.Series]:
        if samples is None or len(samples) == 0:
            return None

        results: Dict[Any, str | None] = {}

        completion_queue: asyncio.Queue[None] = asyncio.Queue()

        async def worker(row_idx: Any, row: pd.Series) -> None:
            nonlocal results
            try:
                sample_str = "\n".join(f"{col}: {row[col]}" for col in row.index)

                task_description = self.task_description

                query = (
                    f"Task description:\n{task_description}\n\n"
                    f"Policy:\n{policy}\n\n"
                    f"Sample:\n{sample_str}\n\n"
                )

                async with self._llm_semaphore:
                    response = await llm.respond(
                        query=query,
                        llm_priority=self.predict_llmc,
                        instructions=POLICY_PREDICT_INSTRUCTIONS,
                        response_format=Answer,
                        temperature=self.predict_temperature,
                    )

                await token_counter.append(
                    provider=response.provider_model.provider,
                    model=response.provider_model.model,
                    value=response.total_tokens,
                    caller="Policy Induction._single_policy_predict",
                )
                if response.response is None:
                    raise LLMError("No response from LLM")

                if response.average_confidence is not None:
                    logger.debug(
                        f"Confidence: {response.average_confidence} "
                        f"Policy: '{policy}' for sample: {sample_str}"
                    )
                else:
                    logger.debug(
                        "Could not track confidence of answer. "
                        f"Policy: '{policy}' for sample: {sample_str}"
                    )

                txt = str(response.response.answer).strip().upper()
                txt = txt.strip().strip('".,;:')  # light cleanup

                if txt in {"YES", "NO"}:
                    results[row_idx] = txt
                else:
                    if "YES" in txt:
                        results[row_idx] = "YES"
                    elif "NO" in txt:
                        results[row_idx] = "NO"
                    else:
                        logger.warning(
                            "Unexpected model output for sample %s: %r",
                            row_idx,
                            response,
                        )
                        results[row_idx] = None

            except asyncio.CancelledError:
                pass
            except Exception:
                logger.warning(
                    "Error in PolicyInduction worker prediction", exc_info=True
                )
                results[row_idx] = None
            finally:
                completion_queue.put_nowait(None)

        it = iter(samples.iterrows())
        in_flight = 0

        try:
            async with asyncio.TaskGroup() as tg:
                for _ in range(self.llm_semaphore_limit):
                    try:
                        idx, row = next(it)
                    except StopIteration:
                        break
                    tg.create_task(worker(idx, row))
                    in_flight += 1

                while in_flight > 0:
                    await completion_queue.get()
                    in_flight -= 1

                    try:
                        idx, row = next(it)
                    except StopIteration:
                        continue
                    tg.create_task(worker(idx, row))
                    in_flight += 1
        finally:
            if len(results) == 0:
                return None

            out = pd.Series([None] * len(samples), index=samples.index, dtype="object")
            for k, v in results.items():
                if k in out.index:
                    out.at[k] = v

            return out

    async def _score_policies(self) -> None:
        if self._X is None or self._y is None:
            raise ValueError("X and y must be set")

        self._check_policy_memory()

        temp_memory = self._policy_memory.copy(deep=True)

        not_scored_idx = temp_memory.index[temp_memory["predictions"].isna()]
        num_not_scored = not_scored_idx.size

        predictions_buffer: Dict[Any, Any] = {}

        completions = 0

        for policy_index in not_scored_idx:
            try:
                pdf = temp_memory
                policy = str(pdf.at[policy_index, "policy"])
                samples = self._X

                result = await self._single_policy_predict(
                    policy=policy,
                    samples=samples,
                    token_counter=self._token_counter,
                )

                if result is not None:
                    predictions_buffer[policy_index] = result

            except asyncio.CancelledError:
                pass
            except Exception:
                logger.warning(
                    "Error in PolicyInduction worker scoring policy", exc_info=True
                )
            finally:
                completions += 1
                if completions % self.p_predict_update_interval == 0:
                    logger.info(
                        f"Scored {completions} policies out of {num_not_scored}"
                    )

        for idx, pred in predictions_buffer.items():
            temp_memory.at[idx, "predictions"] = pred

        self._policy_memory = temp_memory

    def _set_weight(self) -> None:
        pass

    async def _build_PolicyInduction(self) -> None:
        X = self._X
        y = self._y

        if X is None or y is None:
            raise ValueError("X, y must be set")

        logger.info("Generating Policies")
        await self._generate_policies()
        logger.info(f"Generated {self._policy_memory.shape[0]} policies")

        logger.info("Scoring Policies")
        await self._score_policies()

        logger.info("Setting policy weight")
        self._set_weight()

    async def fit(
        self,
        X: pd.DataFrame | None = None,
        y: Sequence[str] | None = None,
        *,
        copy_data: bool = True,
        reset: bool = False,
    ) -> Self:
        """Fit the PolicyInduction to the data.

        Args:
            X: Training features. Required on first run or with reset=True.
            y: Training labels. Required on first run or with reset=True.
            copy_data: Whether to copy input data.
            reset: Clear existing state and restart forest generation.

        Returns:
            Self: Updated PolicyInduction.

        Raises:
            ValueError: If data requirements aren't met or invalid reset usage.
        """
        if reset:
            if X is None or y is None:
                raise ValueError("reset=True requires X and y")
            self._set_data(X, y, copy_data)

        else:
            if X is not None or y is not None:
                if self._X is not None or self._y is not None:
                    raise ValueError(
                        "Data already set on PolicyInduction. "
                        "Explicitly pass reset=True "
                        "to replace data and restart training."
                    )
                if X is None or y is None:
                    raise ValueError("Both X and y must be provided together")
                self._set_data(X, y, copy_data)

        if self._X is None or self._y is None:
            raise ValueError(
                "No data found. Provide X and y " "(or reset=True with X,y)"
            )

        await self._build_PolicyInduction()
        logger.info("PolicyInductioin settled successfully")
        return self
